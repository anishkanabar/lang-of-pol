2022-02-16 00:33:14,545 - speechbrain.core - INFO - Beginning experiment!
2022-02-16 00:33:14,545 - speechbrain.core - INFO - Experiment folder: results/train_wav2vec2_char/seed_1986/trial_10
2022-02-16 00:33:14,988 - speechbrain.utils.superpowers - DEBUG - appdirs==1.4.4
-e git+git@github.com:UrbanResiliencyInitiative/lang-of-pol.git@83a312f417d49c1468eb1193b1cc840410b5f149#egg=asr_dataset&subdirectory=asr/data/asr_dataset
attrs==21.4.0
audioread==2.1.9
black==19.10b0
certifi==2021.10.8
cffi==1.15.0
cfgv==3.3.1
charset-normalizer==2.0.11
click==8.0.3
decorator==5.1.1
distlib==0.3.4
entrypoints==0.3
filelock==3.4.2
flake8==3.7.9
huggingface-hub==0.4.0
HyperPyYAML==1.0.0
identify==2.4.7
idna==3.3
joblib==1.1.0
librosa==0.8.1
llvmlite==0.38.0
mccabe==0.6.1
more-itertools==8.12.0
nodeenv==1.6.0
numba==0.55.1
numpy==1.21.5
packaging==21.3
pandas==1.4.0
pathspec==0.9.0
platformdirs==2.4.1
pluggy==0.13.1
pooch==1.6.0
pre-commit==2.17.0
py==1.11.0
pycodestyle==2.5.0
pycparser==2.21
pyflakes==2.1.1
pyparsing==3.0.7
pytest==5.4.1
python-dateutil==2.8.2
pytz==2021.3
PyYAML==6.0
regex==2022.1.18
requests==2.27.1
resampy==0.2.2
ruamel.yaml==0.17.20
ruamel.yaml.clib==0.2.6
sacremoses==0.0.47
scikit-learn==1.0.2
scipy==1.7.3
sentencepiece==0.1.96
six==1.16.0
SoundFile==0.10.3.post1
-e git+git@github.com:UrbanResiliencyInitiative/lang-of-pol.git@83a312f417d49c1468eb1193b1cc840410b5f149#egg=speechbrain&subdirectory=asr/models/speechbrain
threadpoolctl==3.1.0
tokenizers==0.11.4
toml==0.10.2
torch==1.10.0
torchaudio==0.10.0
tqdm==4.62.3
transformers==4.16.2
typed-ast==1.5.2
typing-extensions==4.0.1
urllib3==1.26.8
virtualenv==20.13.0
wcwidth==0.2.5
yamllint==1.23.0


2022-02-16 00:33:15,024 - speechbrain.utils.superpowers - DEBUG - 83a312f


2022-02-16 00:33:16,527 - asr.dataset.utterance - INFO - Discarding 0 missing mp3s.
2022-02-16 00:33:16,970 - asr.dataset.utterance - INFO - Discarding 0 too_short mp3s.
2022-02-16 00:33:16,975 - asr.dataset - INFO - atczero dataset stats:
2022-02-16 00:33:16,975 - asr.dataset - INFO - 	Row count = 30436
2022-02-16 00:33:16,975 - asr.dataset - INFO - 	Min duration = 0.12 (sec)
2022-02-16 00:33:16,975 - asr.dataset - INFO - 	Max duration = 111.98 (sec)
2022-02-16 00:33:16,976 - asr.dataset - INFO - 	Mean duration = 3.10 (sec)
2022-02-16 00:33:16,976 - asr.dataset - INFO - 	Stdev duration = 1.99 (sec)
2022-02-16 00:33:16,977 - asr.dataset - INFO - 	Total duration = 1 days 02:11:15.222770
2022-02-16 00:33:17,775 - asr.dataset.utterance - INFO - Discarding 1 missing mp3s.
2022-02-16 00:33:36,638 - asr.dataset.utterance - INFO - Discarding 0 corrupted mp3s
2022-02-16 00:33:36,645 - asr.dataset - INFO - atczero dataset stats:
2022-02-16 00:33:36,645 - asr.dataset - INFO - 	Row count = 30435
2022-02-16 00:33:36,646 - asr.dataset - INFO - 	Min duration = 0.12 (sec)
2022-02-16 00:33:36,646 - asr.dataset - INFO - 	Max duration = 111.98 (sec)
2022-02-16 00:33:36,646 - asr.dataset - INFO - 	Mean duration = 3.10 (sec)
2022-02-16 00:33:36,647 - asr.dataset - INFO - 	Stdev duration = 1.99 (sec)
2022-02-16 00:33:36,647 - asr.dataset - INFO - 	Total duration = 1 days 02:11:13.362770
2022-02-16 00:33:36,667 - bpc_prepare - INFO - Preparing results/train_wav2vec2_char/seed_1986/trial_10/train.csv...
2022-02-16 00:33:36,796 - bpc_prepare - INFO - Preparing results/train_wav2vec2_char/seed_1986/trial_10/dev.csv...
2022-02-16 00:33:36,826 - bpc_prepare - INFO - Preparing results/train_wav2vec2_char/seed_1986/trial_10/test.csv...
2022-02-16 00:33:37,271 - speechbrain.dataio.encoder - DEBUG - Would load categorical encoding from results/train_wav2vec2_char/seed_1986/trial_10/save/label_encoder.txt, but file doesn't exist yet.
2022-02-16 00:33:37,642 - speechbrain.dataio.encoder - INFO - Moving label 'G' from index 0, because '<blank>' was put at its place.
2022-02-16 00:33:37,642 - speechbrain.dataio.encoder - INFO - Moving label 'O' from index 1, because '<bos>' was put at its place.
2022-02-16 00:33:37,642 - speechbrain.dataio.encoder - INFO - Moving label 'D' from index 2, because '<eos>' was put at its place.
2022-02-16 00:33:37,648 - speechbrain.dataio.encoder - INFO - Load called, but CTCTextEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.
2022-02-16 00:33:37,649 - speechbrain.dataio.encoder - DEBUG - Loaded categorical encoding from results/train_wav2vec2_char/seed_1986/trial_10/save/label_encoder.txt
2022-02-16 00:33:37,649 - speechbrain.core - INFO - Info: auto_mix_prec arg overridden by command line input
2022-02-16 00:33:37,649 - speechbrain.core - INFO - Info: ckpt_interval_minutes arg from hparam file is used
2022-02-16 00:33:40,884 - speechbrain.core - INFO - 317.6M trainable parameters in ASR
2022-02-16 00:33:40,886 - speechbrain.utils.checkpoints - INFO - Would load a checkpoint here, but none found yet.
2022-02-16 00:33:40,886 - speechbrain.utils.epoch_loop - INFO - Going into epoch 1
2022-02-16 00:33:43,363 - speechbrain.core - WARNING - Loss is nan.
2022-02-16 00:33:43,402 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,403 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,404 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,404 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,405 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,406 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,406 - speechbrain.core - WARNING - Patience not yet exhausted, ignoring this batch.
2022-02-16 00:33:43,430 - speechbrain.core - WARNING - Loss is nan.
2022-02-16 00:33:43,460 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,463 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,464 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,464 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,465 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,466 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,466 - speechbrain.core - WARNING - Patience not yet exhausted, ignoring this batch.
2022-02-16 00:33:43,491 - speechbrain.core - WARNING - Loss is nan.
2022-02-16 00:33:43,522 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,523 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,524 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,524 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,525 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,526 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,526 - speechbrain.core - WARNING - Patience not yet exhausted, ignoring this batch.
2022-02-16 00:33:43,551 - speechbrain.core - WARNING - Loss is nan.
2022-02-16 00:33:43,582 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,583 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,584 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,585 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,586 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,586 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-16 00:33:43,587 - speechbrain.core - ERROR - Exception:
Traceback (most recent call last):
  File "ctc/train_with_wav2vec.py", line 339, in <module>
    asr_brain.fit(
  File "/project/graziul/ra/echandler/repo/asr/models/speechbrain/speechbrain/core.py", line 1030, in fit
    loss = self.fit_batch(batch)
  File "ctc/train_with_wav2vec.py", line 104, in fit_batch
    if self.check_gradients(loss):
  File "/project/graziul/ra/echandler/repo/asr/models/speechbrain/speechbrain/core.py", line 886, in check_gradients
    raise ValueError(
ValueError: Loss is not finite and patience is exhausted. To debug, wrap `fit()` with autograd's `detect_anomaly()`, e.g.

with torch.autograd.detect_anomaly():
	brain.fit(...)
