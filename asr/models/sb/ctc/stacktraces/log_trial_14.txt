2022-02-19 02:09:16,866 - speechbrain.core - INFO - Beginning experiment!
2022-02-19 02:09:16,866 - speechbrain.core - INFO - Experiment folder: results/train_wav2vec2_char/seed_1986/trial_14
2022-02-19 02:09:18,103 - speechbrain.utils.superpowers - DEBUG - appdirs==1.4.4
-e git+ssh://git@github.com/UrbanResiliencyInitiative/lang-of-pol.git@fc7a1bd37d0db4409a513d159f23096ef115398b#egg=asr_dataset&subdirectory=asr/data/asr_dataset
attrs==21.4.0
audioread==2.1.9
black==19.10b0
certifi==2021.10.8
cffi==1.15.0
cfgv==3.3.1
charset-normalizer==2.0.12
click==8.0.4
decorator==5.1.1
distlib==0.3.4
entrypoints==0.3
filelock==3.6.0
flake8==3.7.9
huggingface-hub==0.4.0
HyperPyYAML==1.0.0
identify==2.4.10
idna==3.3
joblib==1.1.0
librosa==0.9.1
llvmlite==0.38.0
mccabe==0.6.1
more-itertools==8.12.0
nodeenv==1.6.0
numba==0.55.1
numpy==1.21.5
packaging==21.3
pandas==1.4.1
pathspec==0.9.0
platformdirs==2.5.0
pluggy==0.13.1
pooch==1.6.0
pre-commit==2.17.0
py==1.11.0
pycodestyle==2.5.0
pycparser==2.21
pyflakes==2.1.1
pyparsing==3.0.7
pytest==5.4.1
python-dateutil==2.8.2
pytz==2021.3
PyYAML==6.0
regex==2022.1.18
requests==2.27.1
resampy==0.2.2
ruamel.yaml==0.17.21
ruamel.yaml.clib==0.2.6
sacremoses==0.0.47
scikit-learn==1.0.2
scipy==1.8.0
sentencepiece==0.1.96
six==1.16.0
SoundFile==0.10.3.post1
-e git+ssh://git@github.com/UrbanResiliencyInitiative/lang-of-pol.git@fc7a1bd37d0db4409a513d159f23096ef115398b#egg=speechbrain&subdirectory=asr/models/speechbrain
threadpoolctl==3.1.0
tokenizers==0.11.5
toml==0.10.2
torch==1.10.0
torchaudio==0.10.0
tqdm==4.62.3
transformers==4.16.2
typed-ast==1.5.2
typing_extensions==4.1.1
urllib3==1.26.8
virtualenv==20.13.1
wcwidth==0.2.5
yamllint==1.23.0


2022-02-19 02:09:18,189 - speechbrain.utils.superpowers - DEBUG - fc7a1bd


2022-02-19 02:09:19,869 - asr.etl - INFO - atczero-extracted dataset stats:
2022-02-19 02:09:19,869 - asr.etl - INFO - 	Row count = 30436
2022-02-19 02:09:19,869 - asr.etl - INFO - 	Min duration = 0.12 (sec)
2022-02-19 02:09:19,870 - asr.etl - INFO - 	Max duration = 111.98 (sec)
2022-02-19 02:09:19,870 - asr.etl - INFO - 	Mean duration = 3.10 (sec)
2022-02-19 02:09:19,870 - asr.etl - INFO - 	Stdev duration = 1.99 (sec)
2022-02-19 02:09:19,871 - asr.etl - INFO - 	Total duration = 1 days 02:11:15.222770
2022-02-19 02:09:19,896 - asr.etl - INFO - Discarding 0 missing audios.
2022-02-19 02:09:20,432 - asr.etl - INFO - Discarding 0 too_short mp3s.
2022-02-19 02:09:33,959 - asr.etl - INFO - Discarding 0 corrupted mp3s
2022-02-19 02:09:33,966 - asr.etl - INFO - Writing utterance audio clips.
2022-02-19 02:09:33,969 - asr.etl - DEBUG - Writing file 0 of 52
2022-02-19 02:09:37,331 - asr.etl - DEBUG - Writing file 1 of 52
2022-02-19 02:09:40,225 - asr.etl - DEBUG - Writing file 2 of 52
2022-02-19 02:09:42,338 - asr.etl - DEBUG - Writing file 3 of 52
2022-02-19 02:09:46,119 - asr.etl - DEBUG - Writing file 4 of 52
2022-02-19 02:09:48,473 - asr.etl - DEBUG - Writing file 5 of 52
2022-02-19 02:09:51,199 - asr.etl - DEBUG - Writing file 6 of 52
2022-02-19 02:09:53,007 - asr.etl - DEBUG - Writing file 7 of 52
2022-02-19 02:09:57,816 - asr.etl - DEBUG - Writing file 8 of 52
2022-02-19 02:10:01,620 - asr.etl - DEBUG - Writing file 9 of 52
2022-02-19 02:10:04,775 - asr.etl - DEBUG - Writing file 10 of 52
2022-02-19 02:10:06,647 - asr.etl - DEBUG - Writing file 11 of 52
2022-02-19 02:10:08,499 - asr.etl - DEBUG - Writing file 12 of 52
2022-02-19 02:10:12,429 - asr.etl - DEBUG - Writing file 13 of 52
2022-02-19 02:10:15,203 - asr.etl - DEBUG - Writing file 14 of 52
2022-02-19 02:10:17,882 - asr.etl - DEBUG - Writing file 15 of 52
2022-02-19 02:10:19,808 - asr.etl - DEBUG - Writing file 16 of 52
2022-02-19 02:10:22,130 - asr.etl - DEBUG - Writing file 17 of 52
2022-02-19 02:10:23,629 - asr.etl - DEBUG - Writing file 18 of 52
2022-02-19 02:10:26,542 - asr.etl - DEBUG - Writing file 19 of 52
2022-02-19 02:10:28,346 - asr.etl - DEBUG - Writing file 20 of 52
2022-02-19 02:10:30,977 - asr.etl - DEBUG - Writing file 21 of 52
2022-02-19 02:10:33,307 - asr.etl - DEBUG - Writing file 22 of 52
2022-02-19 02:10:34,876 - asr.etl - DEBUG - Writing file 23 of 52
2022-02-19 02:10:36,107 - asr.etl - DEBUG - Writing file 24 of 52
2022-02-19 02:10:38,380 - asr.etl - DEBUG - Writing file 25 of 52
2022-02-19 02:10:42,769 - asr.etl - DEBUG - Writing file 26 of 52
2022-02-19 02:10:48,358 - asr.etl - DEBUG - Writing file 27 of 52
2022-02-19 02:10:51,285 - asr.etl - DEBUG - Writing file 28 of 52
2022-02-19 02:10:54,625 - asr.etl - DEBUG - Writing file 29 of 52
2022-02-19 02:10:56,445 - asr.etl - DEBUG - Writing file 30 of 52
2022-02-19 02:10:57,776 - asr.etl - DEBUG - Writing file 31 of 52
2022-02-19 02:10:59,970 - asr.etl - DEBUG - Writing file 32 of 52
2022-02-19 02:11:04,398 - asr.etl - DEBUG - Writing file 33 of 52
2022-02-19 02:11:07,047 - asr.etl - DEBUG - Writing file 34 of 52
2022-02-19 02:11:09,077 - asr.etl - DEBUG - Writing file 35 of 52
2022-02-19 02:11:12,128 - asr.etl - DEBUG - Writing file 36 of 52
2022-02-19 02:11:16,373 - asr.etl - DEBUG - Writing file 37 of 52
2022-02-19 02:11:18,987 - asr.etl - DEBUG - Writing file 38 of 52
2022-02-19 02:11:23,850 - asr.etl - DEBUG - Writing file 39 of 52
2022-02-19 02:11:27,206 - asr.etl - DEBUG - Writing file 40 of 52
2022-02-19 02:11:28,447 - asr.etl - DEBUG - Writing file 41 of 52
2022-02-19 02:11:31,133 - asr.etl - DEBUG - Writing file 42 of 52
2022-02-19 02:11:34,446 - asr.etl - DEBUG - Writing file 43 of 52
2022-02-19 02:11:36,068 - asr.etl - DEBUG - Writing file 44 of 52
2022-02-19 02:11:40,138 - asr.etl - DEBUG - Writing file 45 of 52
2022-02-19 02:11:41,927 - asr.etl - DEBUG - Writing file 46 of 52
2022-02-19 02:11:43,650 - asr.etl - DEBUG - Writing file 47 of 52
2022-02-19 02:11:45,677 - asr.etl - DEBUG - Writing file 48 of 52
2022-02-19 02:11:49,879 - asr.etl - DEBUG - Writing file 49 of 52
2022-02-19 02:11:51,782 - asr.etl - DEBUG - Writing file 50 of 52
2022-02-19 02:11:53,722 - asr.etl - DEBUG - Writing file 51 of 52
2022-02-19 02:11:59,591 - asr.etl - INFO - Writing audio took 0:02:25.624625.
2022-02-19 02:12:05,563 - asr.etl - INFO - Discarding 0 missing audios.
2022-02-19 02:12:06,137 - asr.etl - INFO - Discarding 0 too_short mp3s.
2022-02-19 02:12:48,800 - asr.etl - INFO - Discarding 0 corrupted mp3s
2022-02-19 02:12:48,822 - asr.etl - INFO - atczero-transformed dataset stats:
2022-02-19 02:12:48,823 - asr.etl - INFO - 	Row count = 30436
2022-02-19 02:12:48,823 - asr.etl - INFO - 	Min duration = 0.12 (sec)
2022-02-19 02:12:48,824 - asr.etl - INFO - 	Max duration = 111.98 (sec)
2022-02-19 02:12:48,824 - asr.etl - INFO - 	Mean duration = 3.10 (sec)
2022-02-19 02:12:48,825 - asr.etl - INFO - 	Stdev duration = 1.99 (sec)
2022-02-19 02:12:48,825 - asr.etl - INFO - 	Total duration = 1 days 02:11:15.222770
2022-02-19 02:12:48,828 - asr.etl.atczero - DEBUG - Dropped data columns: Index(['location', 'year', 'month', 'day', 'fileStartTime', 'speaker',
       'recipient', 'text', 'comment', 'transcriber', 'offset', 'duration',
       'original_audio', 'audio'],
      dtype='object')
2022-02-19 02:12:57,293 - asr.etl - INFO - atczero-loaded dataset stats:
2022-02-19 02:12:57,294 - asr.etl - INFO - 	Row count = 30436
2022-02-19 02:12:57,294 - asr.etl - INFO - 	Min duration = 0.12 (sec)
2022-02-19 02:12:57,294 - asr.etl - INFO - 	Max duration = 111.98 (sec)
2022-02-19 02:12:57,294 - asr.etl - INFO - 	Mean duration = 3.10 (sec)
2022-02-19 02:12:57,295 - asr.etl - INFO - 	Stdev duration = 1.99 (sec)
2022-02-19 02:12:57,295 - asr.etl - INFO - 	Total duration = 1 days 02:11:15.222770
2022-02-19 02:12:57,314 - bpc_prepare - INFO - Preparing results/train_wav2vec2_char/seed_1986/trial_14/train.csv...
2022-02-19 02:12:57,521 - bpc_prepare - INFO - Preparing results/train_wav2vec2_char/seed_1986/trial_14/dev.csv...
2022-02-19 02:12:57,548 - bpc_prepare - INFO - Preparing results/train_wav2vec2_char/seed_1986/trial_14/test.csv...
2022-02-19 02:12:58,212 - speechbrain.dataio.encoder - DEBUG - Would load categorical encoding from results/train_wav2vec2_char/seed_1986/trial_14/save/label_encoder.txt, but file doesn't exist yet.
2022-02-19 02:12:58,636 - speechbrain.dataio.encoder - INFO - Moving label 'G' from index 0, because '<blank>' was put at its place.
2022-02-19 02:12:58,636 - speechbrain.dataio.encoder - INFO - Moving label 'O' from index 1, because '<bos>' was put at its place.
2022-02-19 02:12:58,636 - speechbrain.dataio.encoder - INFO - Moving label 'D' from index 2, because '<eos>' was put at its place.
2022-02-19 02:12:58,638 - speechbrain.dataio.encoder - INFO - Load called, but CTCTextEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.
2022-02-19 02:12:58,639 - speechbrain.dataio.encoder - DEBUG - Loaded categorical encoding from results/train_wav2vec2_char/seed_1986/trial_14/save/label_encoder.txt
2022-02-19 02:12:58,640 - speechbrain.core - INFO - Info: auto_mix_prec arg overridden by command line input
2022-02-19 02:12:58,640 - speechbrain.core - INFO - Info: ckpt_interval_minutes arg from hparam file is used
2022-02-19 02:13:03,026 - speechbrain.core - INFO - 317.6M trainable parameters in ASR
2022-02-19 02:13:03,031 - speechbrain.utils.checkpoints - INFO - Would load a checkpoint here, but none found yet.
2022-02-19 02:13:03,031 - speechbrain.utils.epoch_loop - INFO - Going into epoch 1
2022-02-19 02:13:07,031 - speechbrain.core - WARNING - Loss is nan.
2022-02-19 02:13:07,082 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,083 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,085 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,085 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,087 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,087 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,088 - speechbrain.core - WARNING - Patience not yet exhausted, ignoring this batch.
2022-02-19 02:13:07,130 - speechbrain.core - WARNING - Loss is nan.
2022-02-19 02:13:07,181 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,181 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,183 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,184 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,185 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,186 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,186 - speechbrain.core - WARNING - Patience not yet exhausted, ignoring this batch.
2022-02-19 02:13:07,232 - speechbrain.core - WARNING - Loss is nan.
2022-02-19 02:13:07,283 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,284 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,285 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,286 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,288 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,288 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,288 - speechbrain.core - WARNING - Patience not yet exhausted, ignoring this batch.
2022-02-19 02:13:07,327 - speechbrain.core - WARNING - Loss is nan.
2022-02-19 02:13:07,377 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,378 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,380 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,380 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,382 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,382 - speechbrain.core - WARNING - Parameter is not finite: Parameter containing:
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan], device='cuda:0',
       requires_grad=True)
2022-02-19 02:13:07,383 - speechbrain.core - ERROR - Exception:
Traceback (most recent call last):
  File "/share/data/speech/Data/echandler/repos/uri/asr/models/speechbrain/recipes/BPC/ctc/train_with_wav2vec.py", line 342, in <module>
    asr_brain.fit(
  File "/share/data/speech/Data/echandler/repos/uri/asr/models/speechbrain/speechbrain/core.py", line 1030, in fit
    loss = self.fit_batch(batch)
  File "/share/data/speech/Data/echandler/repos/uri/asr/models/speechbrain/recipes/BPC/ctc/train_with_wav2vec.py", line 104, in fit_batch
    if self.check_gradients(loss):
  File "/share/data/speech/Data/echandler/repos/uri/asr/models/speechbrain/speechbrain/core.py", line 886, in check_gradients
    raise ValueError(
ValueError: Loss is not finite and patience is exhausted. To debug, wrap `fit()` with autograd's `detect_anomaly()`, e.g.

with torch.autograd.detect_anomaly():
	brain.fit(...)
