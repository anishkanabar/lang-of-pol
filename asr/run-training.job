#!/bin/bash

#
# USAGE:
# From the terminal, run:
# sbatch run-training.job <path_to_conda_env> 
#

#
#OPIONS FOR JOB ID:
#SBATCH --job-name=train-asr
#
#OPTIONS FOR EMAIL:
#SBATCH --output=/project/graziul/ra/%u/slurm_output/%j.%N.stdout
#SBATCH --error=/project/graziul/ra/%u/slurm_output/%j.%N.stderr
#
#OPTIONS FOR PARTITION:
#SBATCH --account=pi-graziul
#
#OPTIONS FOR JOB SIZE:
#SBATCH --partition=gpu
# Always set ntasks==gpus and ntasks-per-gpu=1
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --ntasks=1
#SBATCH --ntasks-per-gpu=1
#SBATCH --mem-per-cpu=12G
#SBATCH --time=06:00:00
#

cd "$(dirname "$0")"
local_flag="$1"
env_dir="$2"
dataset_dir="$3"
logs_dir="$4"

if [ ! -e "$env_dir" ];
then
    echo "Conda environment not found. See 'create_env.sh'. Exiting."
    exit 1
fi

echo "Listing gpu nodes"
sh show_cuda_devices.sh
conda run -p "$env_dir" python tf_devices.py

echo "Running model"
dataset='radio'
conda run -p "$env_dir" python train_deepspeech.py "$local_flag" "$dataset" "$dataset_dir" "$logs_dir"

