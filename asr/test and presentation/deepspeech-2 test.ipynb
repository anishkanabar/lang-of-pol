{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af8bf2f4-ce06-4dc8-a06e-93265099c3de",
   "metadata": {},
   "source": [
    "# __DEEPSPEECH @2 TEST__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c218ba5d-d030-4f2d-8fa8-772443a78257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepasr as asr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from dataset_radio import RadioDataset\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e96e6d-8dad-4e64-a936-361685ebc3a7",
   "metadata": {},
   "source": [
    "#### __LOAD MODEL__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c07863-372d-4320-b39e-ab5e9983d861",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:28:06.921344: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:From /project/graziul/ra/shiyanglai/experiment2/lang-of-pol/asr/test and presentation/deepasr/pipeline/ctc_pipeline.py:354: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "use distribute.MultiWorkerMirroredStrategy instead\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/device:CPU:0',)\n",
      "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:CPU:0',), communication = CommunicationImplementation.AUTO\n",
      "Training using multiple GPUs\n"
     ]
    }
   ],
   "source": [
    "model = asr.pipeline.load('/project/graziul/ra/echandler/job_2919943/checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32ed862-9e6f-4ab6-959c-dd096dcccad5",
   "metadata": {},
   "source": [
    "#### __PREDICTION EXAMPLE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716b21d1-6669-4297-9956-c786682ba0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarding 11017 missing mp3s\n",
      "Discarding 98427 too-short mp3s\n"
     ]
    }
   ],
   "source": [
    "# load transcript data\n",
    "dataset_loader = RadioDataset()\n",
    "dataset = dataset_loader.load_transcripts('/project/graziul/transcripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73abd29d-4db6-4959-a878-ead08bc55f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select one utterance as the example\n",
    "index = np.random.randint(dataset.shape[0])\n",
    "sample = dataset.iloc[index]\n",
    "test_file = sample['path']\n",
    "test_transcript = sample['transcripts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9de41314-f923-4e9a-affa-2c7502df6a22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73297\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (73297,161) into shape (115,161)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/ipykernel_2719845/2677840093.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_error_rates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/project/graziul/ra/shiyanglai/experiment2/lang-of-pol/asr/test and presentation/deepasr/evaluate/evaluate.py\u001b[0m in \u001b[0;36mcalculate_error_rates\u001b[0;34m(ctc_pipeline, data, return_metrics)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscript\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transcripts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctc_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         batch_metrics = get_metrics(sources=prediction,\n\u001b[1;32m     20\u001b[0m                                     destinations=[transcript])\n",
      "\u001b[0;32m/project/graziul/ra/shiyanglai/experiment2/lang-of-pol/asr/test and presentation/deepasr/pipeline/ctc_pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, audio, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m         features = self.features_extractor.make_features(\n\u001b[1;32m    322\u001b[0m             read_audio(audio, sample_rate=self.sample_rate, mono=self.mono))\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0min_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         pred_model = Model(inputs=self._model.get_layer('the_input').output,\n",
      "\u001b[0;32m/project/graziul/ra/shiyanglai/experiment2/lang-of-pol/asr/test and presentation/deepasr/features/feature_extractor.py\u001b[0m in \u001b[0;36malign\u001b[0;34m(arrays, features_shape, default)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mtime_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mtime_dim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (73297,161) into shape (115,161)"
     ]
    }
   ],
   "source": [
    "asr.evaluate.calculate_error_rates(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc066ea-ee22-4b09-8c48-2ccdd2b590cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f64af-5527-4c50-b12c-b6ad577fbd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e6b293-ed9c-437f-bc80-b3210f2fe5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
