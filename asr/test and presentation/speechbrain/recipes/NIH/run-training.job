#!/bin/bash

#
# USAGE:
# From the terminal, run:
# sbatch run-training.job <path_to_conda_env>
#

#
#OPIONS FOR JOB ID:
#SBATCH --job-name=train-sb
#
#OPTIONS FOR EMAIL:
#SBATCH --output=/project/graziul/ra/%u/slurm_output/%j.%N.stdout
#SBATCH --error=/project/graziul/ra/%u/slurm_output/%j.%N.stderr
#
#OPTIONS FOR PARTITION:
#SBATCH --account=pi-graziul
#
#OPTIONS FOR JOB SIZE:
#SBATCH --partition=gpu
# Always set ntasks==gpus and ntasks-per-gpu=1
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --ntasks=1
#SBATCH --ntasks-per-gpu=1
#SBATCH --mem-per-cpu=24G
#SBATCH --time=18:00:00
#

python Tokenizer/train.py Tokenizer/hparams/tokenizer_bpe5000.yaml
