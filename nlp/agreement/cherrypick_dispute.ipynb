{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asr_dataset.police import BpcETL, AmbiguityStrategy\n",
    "from asr_dataset.constants import Cluster\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('asr').setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl = BpcETL(Cluster.AI, \n",
    "    filter_inaudible=False, \n",
    "    filter_numeric=False, \n",
    "    filter_uncertain=False,\n",
    "    ambiguity=AmbiguityStrategy.ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = etl.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(end = data['offset'] + data['duration'])\n",
    "candidates = data.merge(data, on='original_audio')\n",
    "# remove \"reverse duplicates\": e.g. when row 1 = (x,y) and row 2 = (y,x)\n",
    "# by keeping the version where x is on the left of the join\n",
    "# conveniently this makes computing overlap easier\n",
    "overlaps = (candidates['offset_x'] <= candidates['offset_y']) \\\n",
    "            & (candidates['end_x'] >= candidates['offset_y'])\n",
    "same_scriber = candidates['transcriber_x'] == candidates['transcriber_y']\n",
    "candidates = candidates.loc[overlaps & ~same_scriber]\n",
    "n_candidates = pd.concat([candidates['audio_x'],candidates['audio_y']]).nunique()\n",
    "print(f'Found {n_candidates} that overlap somewhat.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERLAP_THRESHOLD = .5   # arbitrary\n",
    "intersect = candidates['end_x'] - candidates['offset_y']\n",
    "overlap = pd.concat([candidates['duration_y'], intersect], axis=1).apply(min, axis=1)\n",
    "shorter = candidates[['duration_x','duration_y']].apply(min, axis=1)\n",
    "candidates = candidates.loc[(overlap / shorter) > OVERLAP_THRESHOLD]\n",
    "n_candidates = pd.concat([candidates['audio_x'],candidates['audio_y']]).nunique()\n",
    "print(f'Found {n_candidates} that overlap > 50%.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    pick = candidates[['text_x','text_y']].sample().values\n",
    "    print(f\"{pick[0,0]} vs {pick[0,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cherry Pick 1: Negation\n",
    "cherry = candidates.loc[candidates['text_x'].str.contains('FEMALE IN YOUR CAR').fillna(False)]\n",
    "cherry = cherry.loc[cherry['text_x'].str.contains(\"DON\") & cherry['text_y'].str.contains(\"DO HAVE\")]\n",
    "for tup in cherry[['audio_x','audio_y','text_x','text_y']].drop_duplicates().itertuples():\n",
    "    print(f\"{tup.audio_x}\")\n",
    "    print(f\"{tup.text_x}\")\n",
    "    print(f\"{tup.text_y}\")\n",
    "    print(f\"{tup.audio_y}\")\n",
    "    print(\"---\")\n",
    "cherry_audio_x = '/net/projects/uri/data/utterances/Zone1/2018_08_05/201808050001-100238-27730/853366_857758.flac'\n",
    "cherry_audio_y = '/net/projects/uri/data/utterances/Zone1/2018_08_05/201808050001-100238-27730/853366_857758.flac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cherry Pick 2: Shell Casing\n",
    "cherry = candidates.loc[candidates['text_x'].str.contains('SHELL CASING BY THE').fillna(False)]\n",
    "for tup in cherry[['audio_x','audio_y','text_x','text_y']].drop_duplicates().itertuples():\n",
    "    print(f\"{tup.audio_x}\")\n",
    "    print(f\"{tup.text_x}\")\n",
    "    print(f\"{tup.text_y}\")\n",
    "    print(f\"{tup.audio_y}\")\n",
    "    print(\"---\")\n",
    "cherry_audio_x = '/net/projects/uri/data/utterances/Zone8/2018_08_10/201808101202-916683-27158/268396_270685.flac'\n",
    "cherry_audio_y = '/net/projects/uri/data/utterances/Zone8/2018_08_10/201808101202-916683-27158/268522_270528.flac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cherry Pick 3: Traffic Stop vs Shots\n",
    "cherry = candidates.loc[candidates['text_x'].str.contains('TRAFFIC STOP LAWRENCE').fillna(False)]\n",
    "for tup in cherry[['audio_x','audio_y','text_x','text_y']].drop_duplicates().itertuples():\n",
    "    print(f\"{tup.audio_x}\")\n",
    "    print(f\"{tup.text_x}\")\n",
    "    print(f\"{tup.text_y}\")\n",
    "    print(f\"{tup.audio_y}\")\n",
    "    print(\"---\")\n",
    "cherry_audio_x = '/net/projects/uri/data/utterances/Zone1/2018_08_05/201808050359-300564-27730/433621_435561.flac'\n",
    "cherry_audio_y = '/net/projects/uri/data/utterances/Zone1/2018_08_05/201808050359-300564-27730/433755_435281.flac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8cb186c9bbafe12bc9c1d58941f8f1e602b08c22da633db0697eceb79ef4000b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('audio')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
