{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asr_dataset.police import BpcETL, AmbiguityStrategy\n",
    "from asr_dataset.constants import Cluster, DATASET_DIRS\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('asr').setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = Cluster.AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl = BpcETL(cluster,\n",
    "    filter_inaudible=False, \n",
    "    filter_numeric=False, \n",
    "    filter_uncertain=False,\n",
    "    ambiguity=AmbiguityStrategy.ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarding 35880 utts insuitable for VAD\n"
     ]
    }
   ],
   "source": [
    "data = etl.extract()\n",
    "whitelist = pd.read_csv(DATASET_DIRS[cluster]['police_mp3s'] + \"/whitelisted_vad_files.csv\", names=['files'])\n",
    "in_whitelist = data['original_audio'].apply(lambda x: os.path.basename(x)).isin(whitelist['files'])\n",
    "print(f'Discarding {len(data) - in_whitelist.sum()} utts insuitable for VAD')\n",
    "data = data.loc[in_whitelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_len = 20 # ms\n",
    "hop_sec = hop_len / 1000\n",
    "sr = 16000 # hz\n",
    "hop_sam = sr * hop_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(end = data['offset'] + data['duration'])\n",
    "data = data.assign(start_frame = librosa.time_to_frames(data['offset'], sr=16000, hop_length=hop_sam),\n",
    "                    end_frame = librosa.time_to_frames(data['end'], sr=16000, hop_length=hop_sam))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fleiss(data):\n",
    "    # Make binary speech arrays\n",
    "    frame_speech = {}\n",
    "\n",
    "    aud_frames = {}\n",
    "    for aud in data['original_audio'].unique():\n",
    "        if os.path.exists(aud):\n",
    "            n_sec = librosa.get_duration(filename=aud, sr=sr)\n",
    "        else:\n",
    "            n_sec = 30 * 60\n",
    "        aud_frames[aud] = librosa.time_to_frames(n_sec ,sr=sr, hop_length=hop_sam)\n",
    "\n",
    "    for tup in data.itertuples():\n",
    "        aud = tup.original_audio\n",
    "        ts = tup.transcriber\n",
    "        speech = frame_speech.get((aud, ts), np.zeros(aud_frames[aud]))\n",
    "        speech[tup.start_frame : tup.end_frame] += 1\n",
    "        frame_speech[(aud, ts)] = speech\n",
    "    \n",
    "    # Compute total speech and fleiss agreement score\n",
    "    n_annotators = {}\n",
    "    for aud, ts in frame_speech.keys():\n",
    "        n_annotators[aud] = n_annotators.get(aud, 0) + 1\n",
    "\n",
    "    aud_speech = {}\n",
    "    for aud, ts in frame_speech.keys():\n",
    "        speech = aud_speech.get(aud, np.zeros(aud_frames[aud]))\n",
    "        speech += frame_speech[(aud, ts)] > 0  #compare to 0 to avoid double-counting duplicate records\n",
    "        aud_speech[aud] = speech\n",
    "\n",
    "    fleiss_agreement = {}\n",
    "    pct_agreement = {}\n",
    "    for aud in aud_speech.keys():\n",
    "        speech = aud_speech[aud]\n",
    "        na = n_annotators[aud]\n",
    "        non_speech = na - speech\n",
    "        assert((speech <= na).all())\n",
    "        assert((speech >= 0).all())\n",
    "        assert((non_speech >= 0).all())\n",
    "        norm = 1 if na == 1 else (1. / (na * (na - 1)))\n",
    "        fleiss = norm * (speech * (speech - 1) + non_speech * (non_speech - 1))\n",
    "        pct = (speech - 1) * (speech > 0) + (non_speech - 1) * (non_speech > 0)\n",
    "        fleiss_agreement[aud] = fleiss\n",
    "        pct_agreement[aud] = pct\n",
    "\n",
    "    sum_agree = 0\n",
    "    len_agree = 0\n",
    "    sum_speech = 0\n",
    "    sum_pct = 0\n",
    "    for aud, arr in fleiss_agreement.items():\n",
    "        sum_agree += arr.sum()\n",
    "        sum_speech += aud_speech[aud].sum()\n",
    "        sum_pct += pct_agreement[aud].sum()\n",
    "        len_agree += len(arr)\n",
    "    avg_agree = sum_agree / len_agree\n",
    "    p_speech = sum_speech / len_agree\n",
    "    p_silence = 1 - sum_speech / len_agree\n",
    "    print(f'p_speech {p_speech:.3f}, p_nonspeech {p_silence:.3f}')\n",
    "\n",
    "    var_prob = p_speech * p_speech + p_silence * p_silence\n",
    "\n",
    "    kappa = (avg_agree - var_prob) / (1 - var_prob)\n",
    "    pct_agg = sum_pct / len_agree\n",
    "    std_err = np.sqrt(pct_agg * (1 - pct_agg) / (len_agree * (1 - var_prob)*(1 - var_prob)))\n",
    "    ci_low, ci_high = kappa - 1.96 * std_err, kappa + 1.96 * std_err\n",
    "    print(f'Pct Aggreement {pct_agg :.3f}')\n",
    "    print(f'Kappa {kappa:.3f} +/- {1.96 * std_err : .6f}')\n",
    "\n",
    "    return pct_agg, kappa, std_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_speech 0.335, p_nonspeech 0.665\n",
      "Pct Aggreement 0.749\n",
      "Kappa 0.436 +/-  0.000622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7485551337665967, 0.43587702131028944, 0.0003172609721521282)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_fleiss(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fleiss Kappa (rough not universally accepted not context-independent) Rule of Thumb:\n",
    "\n",
    "Kappa | Interpretation\n",
    "--- | ---\n",
    "< 0 | Poor\n",
    ".01 - .20 | Slight\n",
    ".21 - .40 | Fair\n",
    ".41 - .60 | Moderate\n",
    ".61 - .80 | Substantial\n",
    ".81 - 1 | Almost Perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_speech 0.235, p_nonspeech 0.765\n",
      "Pct Aggreement 0.770\n",
      "Kappa 0.361 +/-  0.000940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7704108484145789, 0.36124575914277196, 0.0004796458439563995)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zone1 = data.loc[data['original_audio'].str.contains('Zone1').fillna(False)]\n",
    "compute_fleiss(zone1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_speech 0.335, p_nonspeech 0.665\n",
      "Pct Aggreement 0.828\n",
      "Kappa 0.615 +/-  0.005482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8284432775407504, 0.6151647916358401, 0.002797083703064903)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zone4 = data.loc[data['original_audio'].str.contains('Zone4').fillna(False)]\n",
    "compute_fleiss(zone4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_speech 0.513, p_nonspeech 0.487\n",
      "Pct Aggreement 0.708\n",
      "Kappa 0.415 +/-  0.000972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7077904195526118, 0.4152131618263185, 0.0004957947569327375)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zone8 = data.loc[data['original_audio'].str.contains('Zone8').fillna(False)]\n",
    "compute_fleiss(zone8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len zone 1, 4, 8: 10620, 133, 15164\n"
     ]
    }
   ],
   "source": [
    "print(f\"len zone 1, 4, 8: {len(zone1)}, {len(zone4)}, {len(zone8)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8cb186c9bbafe12bc9c1d58941f8f1e602b08c22da633db0697eceb79ef4000b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
