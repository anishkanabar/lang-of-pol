{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asr_dataset.police import BpcETL, AmbiguityStrategy\n",
    "from asr_dataset.constants import Cluster\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('asr').setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl = BpcETL(Cluster.AI, \n",
    "    filter_inaudible=False, \n",
    "    filter_numeric=False, \n",
    "    filter_uncertain=False,\n",
    "    ambiguity=AmbiguityStrategy.ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = etl.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_len = 20 # ms\n",
    "hop_sec = hop_len / 1000\n",
    "sr = 16000 # hz\n",
    "hop_sam = sr * hop_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(end = data['offset'] + data['duration'])\n",
    "data = data.assign(start_frame = librosa.time_to_frames(data['offset'], sr=16000, hop_length=hop_sam),\n",
    "                    end_frame = librosa.time_to_frames(data['end'], sr=16000, hop_length=hop_sam))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make binary speech arrays\n",
    "frame_speech = {}\n",
    "n_frames = librosa.time_to_frames(30 * 60, sr=sr, hop_length=hop_sam)\n",
    "for tup in data.itertuples():\n",
    "    aud = tup.original_audio\n",
    "    ts = tup.transcriber\n",
    "    speech = frame_speech.get((aud, ts), np.zeros(n_frames))\n",
    "    speech[tup.start_frame : tup.end_frame] += 1\n",
    "    frame_speech[(aud, ts)] = speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute total speech and fleiss agreement score\n",
    "n_annotators = {}\n",
    "for aud, ts in frame_speech.keys():\n",
    "    n_annotators[aud] = n_annotators.get(aud, 0) + 1\n",
    "\n",
    "aud_speech = {}\n",
    "for aud, ts in frame_speech.keys():\n",
    "    speech = aud_speech.get(aud, np.zeros(n_frames))\n",
    "    speech += frame_speech[(aud, ts)] > 0  #compare to 0 to avoid double-counting duplicate records\n",
    "    aud_speech[aud] = speech\n",
    "\n",
    "fleiss_agreement = {}\n",
    "pct_agreement = {}\n",
    "for aud in aud_speech.keys():\n",
    "    speech = aud_speech[aud]\n",
    "    na = n_annotators[aud]\n",
    "    non_speech = na - speech\n",
    "    assert((speech <= na).all())\n",
    "    assert((speech >= 0).all())\n",
    "    assert((non_speech >= 0).all())\n",
    "    norm = 1 if na == 1 else (1. / (na * (na - 1)))\n",
    "    fleiss = norm * (speech * (speech - 1) + non_speech * (non_speech - 1))\n",
    "    pct = (speech - 1) * (speech > 0) + (non_speech - 1) * (non_speech > 0)\n",
    "    fleiss_agreement[aud] = fleiss\n",
    "    pct_agreement[aud] = pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_speech 0.286, p_nonspeech 0.714\n"
     ]
    }
   ],
   "source": [
    "sum_agree = 0\n",
    "len_agree = 0\n",
    "sum_speech = 0\n",
    "sum_pct = 0\n",
    "for aud, arr in fleiss_agreement.items():\n",
    "    sum_agree += arr.sum()\n",
    "    sum_speech += aud_speech[aud].sum()\n",
    "    sum_pct += pct_agreement[aud].sum()\n",
    "    len_agree += len(arr)\n",
    "avg_agree = sum_agree / len_agree\n",
    "p_speech = sum_speech / len_agree\n",
    "p_silence = 1 - sum_speech / len_agree\n",
    "print(f'p_speech {p_speech:.3f}, p_nonspeech {p_silence:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_prob = p_speech * p_speech + p_silence * p_silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa 0.203\n",
      "Pct Aggreement 0.770\n"
     ]
    }
   ],
   "source": [
    "kappa = (avg_agree - var_prob) / (1 - var_prob)\n",
    "print(f'Kappa {kappa:.3f}')\n",
    "print(f'Pct Aggreement {sum_pct / len_agree :.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fleiss Kappa (rough not universally accepted not context-independent) Rule of Thumb:\n",
    "\n",
    "Kappa | Interpretation\n",
    "--- | ---\n",
    "< 0 | Poor\n",
    ".01 - .20 | Slight\n",
    ".21 - .40 | Fair\n",
    ".41 - .60 | Moderate\n",
    ".61 - .80 | Substantial\n",
    ".81 - 1 | Almost Perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8cb186c9bbafe12bc9c1d58941f8f1e602b08c22da633db0697eceb79ef4000b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('audio')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
