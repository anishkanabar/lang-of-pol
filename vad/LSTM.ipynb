{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'losses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/ipykernel_2700276/510749724.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFocalLoss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWeightedFocalLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mStackedLSTM\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStackedLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'losses'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchaudio\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import torchaudio.transforms as T\n",
    "import math\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.patches as patches\n",
    "from glob import glob\n",
    "import util\n",
    "from util import audio_file\n",
    "from util import *\n",
    "from Losses import FocalLoss,WeightedFocalLoss\n",
    "from StackedLSTM import StackedLSTM\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "input_list, labels_list = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StackedLSTM()\n",
    "loss_fn = FocalLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "batch_size = model.batch_size\n",
    "num_samples = input_list.size()[0]//batch_size\n",
    "training_steps = 20\n",
    "idx = 20\n",
    "flag = 0\n",
    "for step in range(training_steps):\n",
    "    input_batch = input_list[idx*batch_size:(idx+1)*batch_size]\n",
    "    labels_batch = labels_list[idx*batch_size:(idx+1)*batch_size]\n",
    "    #idx = (idx+1)%num_samples\n",
    "    print(step)\n",
    "    optimizer.zero_grad()\n",
    "    output_hat = model(input_batch)\n",
    "    #print(output_hat)\n",
    "    print(labels_batch)\n",
    "    print(output_hat)\n",
    "    loss = loss_fn(output_hat, labels_batch)\n",
    "    loss.backward()\n",
    "    #for param in model.parameters():\n",
    "    #    print(param.grad)\n",
    "    print(loss)\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_torch_env",
   "language": "python",
   "name": "new_torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
